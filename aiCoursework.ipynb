{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f11fd27e-3f3d-4e1d-9751-06f776e3d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openpyxl in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from openpyxl) (1.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from scipy) (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rober\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f561e1c-e61d-4510-8012-fe9c57c14991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5365aff8-c869-46c2-9d2f-b52dac40a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data from an Excel file\n",
    "def loadDataFromExcel(filePath, inputColNames, targetColName):\n",
    "    print(f\"Loading data from file: {filePath}\")\n",
    "    \n",
    "    # Read data from the Excel file into a Pandas DataFrame\n",
    "    df = pd.read_excel(filePath)\n",
    "    \n",
    "    # Drop unnecessary columns and rows with NaN values\n",
    "    df = df[inputColNames + [targetColName]].dropna()\n",
    "    \n",
    "    # Handle non-numeric values by converting them to NaN\n",
    "    df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "    \n",
    "    # Extract input features and target values from the DataFrame\n",
    "    inputs = df[inputColNames].values\n",
    "    targets = df[[targetColName]].values\n",
    "    \n",
    "    # Check if there is valid data after processing\n",
    "    if inputs.shape[0] == 0 or targets.shape[0] == 0:\n",
    "        print(\"No valid data found.\")\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    print(f\"Loaded {len(inputs)} rows of data.\")\n",
    "    return inputs, targets\n",
    "\n",
    "# Replaces negatives with 0, keeping non-negatives unchanged\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Return 1 for positive values, 0 otherwise\n",
    "def reluDerivative(x):\n",
    "    return np.where(np.greater(x, 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29a9c0a-1347-4c68-8e4a-5a87ca803897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Multi-Layer Perceptron (MLP) class\n",
    "class MLP:\n",
    "    \n",
    "    def __init__(self, inputSize, hiddenSize, outputSize):\n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.weightsInputHidden = np.random.randn(inputSize, hiddenSize) * np.sqrt(2 / (inputSize + hiddenSize))\n",
    "        # Initialize Bias for Hidden Layer\n",
    "        self.biasHidden = np.zeros((1, hiddenSize))\n",
    "        # Initialize Weights with Xavier/Glorot Initialization for Hidden to Output Layer\n",
    "        self.weightsHiddenOutput = np.random.randn(hiddenSize, outputSize) * np.sqrt(2 / (hiddenSize + outputSize))\n",
    "        # Initialize Bias for Output Layer\n",
    "        self.biasOutput = np.zeros((1, outputSize))\n",
    "\n",
    "        # Initialize Scalers for Input and Target Data\n",
    "        self.scalerInput = StandardScaler()\n",
    "        self.scalerTarget = StandardScaler()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Hidden Layer Input Calculation\n",
    "        self.hiddenLayerInput = np.dot(inputs, self.weightsInputHidden) + self.biasHidden\n",
    "        # Hidden Layer Output Calculation using ReLU activation\n",
    "        self.hiddenLayerOutput = relu(self.hiddenLayerInput)\n",
    "        # Output Layer Input Calculation\n",
    "        self.outputLayerInput = np.dot(self.hiddenLayerOutput, self.weightsHiddenOutput) + self.biasOutput\n",
    "        # Output Layer Output Calculation using ReLU activation\n",
    "        self.predictedOutput = self.outputLayerInput\n",
    "        \n",
    "        return self.predictedOutput\n",
    "\n",
    "    def backward(self, inputs, targets, learningRate):\n",
    "        # Error Calculation\n",
    "        error = targets - self.predictedOutput\n",
    "        # Output Layer Delta Calculation\n",
    "        outputDelta = error\n",
    "        # Hidden Layer Error Calculation\n",
    "        hiddenLayerError = outputDelta.dot(self.weightsHiddenOutput.T)\n",
    "        # Hidden Layer Delta Calculation\n",
    "        hiddenLayerDelta = hiddenLayerError * reluDerivative(self.hiddenLayerOutput)\n",
    "        # Update weights and biases\n",
    "        self.weightsHiddenOutput += self.hiddenLayerOutput.T.dot(outputDelta) * learningRate\n",
    "        self.biasOutput += np.sum(outputDelta, axis=0, keepdims=True) * learningRate\n",
    "        self.weightsInputHidden += inputs.T.dot(hiddenLayerDelta) * learningRate\n",
    "        self.biasHidden += np.sum(hiddenLayerDelta, axis=0, keepdims=True) * learningRate\n",
    "\n",
    "    def train(self, inputs, targets, epochs, learningRate):\n",
    "        # Fit the scaler before training\n",
    "        self.fitScalers(inputs, targets)\n",
    "        inputsNormalised = self.normaliseInput(inputs)\n",
    "\n",
    "        # Begin looping through training epochs\n",
    "        for epoch in range(epochs):\n",
    "            totalLoss = 0\n",
    "            for inputData, target in zip(inputsNormalised, targets):\n",
    "                inputData = np.array([inputData], dtype=float)\n",
    "                target = np.array([target], dtype=float)\n",
    "\n",
    "                # Forward and backward pass\n",
    "                self.forward(inputData)\n",
    "                self.backward(inputData, target, learningRate)\n",
    "\n",
    "                # Calculate and accumulate the loss\n",
    "                loss = np.mean(0.5 * (target - self.predictedOutput)**2)\n",
    "                totalLoss += loss\n",
    "\n",
    "            # Print loss for every 100 epochs\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                if len(inputs) > 0:\n",
    "                    averageLoss = totalLoss / len(inputs)\n",
    "                    print(f\"Epoch: {epoch + 1}, Loss: {averageLoss}\")\n",
    "\n",
    "    def normaliseInput(self, inputs):\n",
    "        return self.scalerInput.transform(inputs)\n",
    "\n",
    "    def normaliseTarget(self, targets):\n",
    "        return self.scalerTarget.transform(targets)\n",
    "\n",
    "    def denormaliseTarget(self, normalisedTargets):\n",
    "        return self.scalerTarget.inverse_transform(normalisedTargets)\n",
    "\n",
    "    def fitScalers(self, inputs, targets):\n",
    "        self.scalerInput.fit(inputs)\n",
    "        self.scalerTarget.fit(targets)\n",
    "\n",
    "    # Make prediction\n",
    "    def predict(self, inputs):\n",
    "        return np.round(self.forward(inputs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8054e99a-4545-42a2-a75d-6756f0de89d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: FEHDataStudent.xlsx\n",
      "Loaded 592 rows of data.\n",
      "Epoch: 100, Loss: 0.24096100922136926\n",
      "Epoch: 200, Loss: 0.18336056223356953\n",
      "Epoch: 300, Loss: 0.16439915070016894\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m inputsNormalised \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mnormaliseInput(inputs)\n\u001b[0;32m     21\u001b[0m targetsNormalised \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mnormaliseTarget(targets)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputsNormalised\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetsNormalised\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumberOfEpochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearningRate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjusted learning rate\u001b[39;00m\n\u001b[0;32m     25\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[7], line 58\u001b[0m, in \u001b[0;36mMLP.train\u001b[1;34m(self, inputs, targets, epochs, learningRate)\u001b[0m\n\u001b[0;32m     55\u001b[0m target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([target], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Forward and backward pass\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputData\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(inputData, target, learningRate)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Calculate and accumulate the loss\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Hidden Layer Input Calculation\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhiddenLayerInput \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweightsInputHidden\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiasHidden\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Hidden Layer Output Calculation using ReLU activation\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhiddenLayerOutput \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhiddenLayerInput)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    numberOfEpochs = 2500\n",
    "    learning_rate = 0.00001\n",
    "    numberOfHiddenNodes = 50\n",
    "    # Specify the file path and column names\n",
    "    filePath = 'FEHDataStudent.xlsx'\n",
    "    inputColumnNames = ['AREA', 'BFIHOST', 'FARL', 'FPEXT', 'LDP', 'PROPWET', 'RMED-1D', 'SAAR']\n",
    "    targetColumnName = 'Index flood'\n",
    "\n",
    "    # Load data from Excel\n",
    "    inputs, targets = loadDataFromExcel(filePath, inputColumnNames, targetColumnName)\n",
    "\n",
    "    mlp = MLP(inputSize=len(inputColumnNames), hiddenSize=numberOfHiddenNodes, outputSize=1)\n",
    "\n",
    "    # Fit both input and target scalers\n",
    "    mlp.fitScalers(inputs, targets)\n",
    "\n",
    "    # Normalize input and target\n",
    "    inputsNormalised = mlp.normaliseInput(inputs)\n",
    "    targetsNormalised = mlp.normaliseTarget(targets)\n",
    "\n",
    "    mlp.train(inputsNormalised, targetsNormalised, epochs=numberOfEpochs, learningRate=learning_rate)  # Adjusted learning rate\n",
    "\n",
    "    predictions = []\n",
    "    mse = 0.0\n",
    "\n",
    "    # Test results\n",
    "    for inputData, target in zip(inputs, targets):\n",
    "        inputDataNormalised = mlp.normaliseInput(np.array([inputData]))\n",
    "        predictionNormalised = mlp.predict(inputDataNormalised)\n",
    "        prediction = mlp.denormaliseTarget(predictionNormalised)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE)\n",
    "        mse += (prediction - target)**2\n",
    "\n",
    "    mse /= len(targets)  # Calculate mean MSE\n",
    "\n",
    "    accuracy = 1 - mse/np.var(targets)  # Calculate accuracy using R-squared\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Variance of Targets: {np.var(targets)}\")\n",
    "    print(f\"Accuracy (R-squared): {accuracy}\")\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(targets, predictions, label='Predictions')\n",
    "    plt.plot([min(targets), max(targets)], [min(targets), max(targets)], '--', color='red', label='Perfect Prediction')\n",
    "    plt.xlabel('Target Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('Model Predictions vs Actual Targets - (Multi-Layer Perceptron | Epoch:'+str(numberOfEpochs)+', LR:'+str(learning_rate)+', NumHidden:'+str(numberOfHiddenNodes)+')')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
